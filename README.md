# pythonsentencetokenizer
Attempt to make a sentence breaker using Python language and the opensource "nltk" python package.
It uses pretrained machine learning models saved as .pickle files which can be loaded at runtime dynamically.

Project Files :
The SentenceBreaker.py file contains all the code.
The SentenceBreaker.zip file is a archive containing redistributable compiled for devices not having Python installed on them.
The zip and .py source code will be updated simultaneously on further updates.

How does it work :
'Punkt' Sentence Tokenizer is the workhorse used for breaking/segmenting/tokenizing the sentences.
It uses pretrained machine learning models saved as .pickle files which can be loaded at runtime dynamically.
Project was built using pyinstaller :) a very nice package to compile any .py script to a redritibutable.

Future Updates :
Features will include ability to build user created models from scratch based on unsupervised learning of a user defined corpus.
Stay Tuned For More.
